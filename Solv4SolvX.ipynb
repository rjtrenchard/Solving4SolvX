{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "#modules and API key\n",
        "!pip install google-cloud-bigquery google-auth google-auth-oauthlib google-auth-httplib2\n",
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "import time\n",
        "from datetime import datetime\n",
        "from datetime import timedelta\n",
        "from google.colab import auth\n",
        "from google.cloud import bigquery\n",
        "\n",
        "#Login to google account used to host BigQuery database\n",
        "auth.authenticate_user()\n",
        "\n",
        "#note for team: replace xxxxxx with your API Key\n",
        "API_KEY = \"xxx\"\n",
        "\n",
        "#Set your projectID and initialize the BigQuery client\n",
        "project_id = 'xxx'\n",
        "client = bigquery.Client(project=project_id)\n",
        "\n",
        "#Setup dataset and table setup in the BigQuery database, then replace these names with yours\n",
        "dataset_id = 'xxx'\n",
        "table_id = 'xxx'\n",
        "\n",
        "url = \"https://api.eia.gov/v2/electricity/rto/region-data/data/?api_key=\" + API_KEY\n",
        "\n",
        "\"\"\"\n",
        "note for team--------------------------------\n",
        "#API route used:\n",
        "\"Electricity\",\n",
        "\"Electric Power Operations (Daily And Hourly)\"\n",
        "\"Hourly Demand, Demand Forecast, Generation, and Interchange\"\n",
        "\n",
        "here's a link for easy access to website: https://www.eia.gov/opendata/browser/electricity/rto/region-data\n",
        "\n",
        "current parameters set within 'params' variable below (which can be modified for filtering directly from api)\n",
        "\n",
        "frequency: hourly\n",
        "\n",
        "facets[respondent]:\n",
        "NW - Pacific Northwest,\n",
        "SCL - Seattle City Light\n",
        "\n",
        "facets[type]:\n",
        "D - Demand,\n",
        "DF - Day-ahead demand forecast,\n",
        "NG - Net Generation\n",
        "\n",
        "start & end\n",
        "2023-04-21T00\" - \"2023-04-22T00\"\n",
        "--------------------------------------\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "6wGZ_ig3WT30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Majority of my submission to the project is on this slide:"
      ],
      "metadata": {
        "id": "mCJDCi8cUstb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#determine date to use\n",
        "now = datetime.today()\n",
        "\n",
        "# create a time delta object to find two days ago\n",
        "delta = timedelta(days=2)\n",
        "\n",
        "# use datetime arithmetic to get two days ago.\n",
        "two_days_ago = now - delta\n",
        "\n",
        "# convert datetime to valid format for the API call\n",
        "def change_to_api_format(dt: datetime) -> str:\n",
        "  return dt.strftime(\"%Y-%m-%dT%H\")\n",
        "\n",
        "now_str = change_to_api_format(now)\n",
        "then_str = change_to_api_format(two_days_ago)\n",
        "\n",
        "params = {\n",
        "    \"frequency\": \"hourly\",\n",
        "    \"data[0]\": \"value\",\n",
        "    \"facets[respondent][]\": [\"NW\", \"SCL\"],\n",
        "    \"facets[type][]\": [\"D\", \"DF\", \"NG\"],\n",
        "    \"sort[0][column]\": \"period\",\n",
        "    \"sort[0][direction]\": \"desc\",\n",
        "    \"start\": then_str,\n",
        "    \"end\": now_str,\n",
        "    \"offset\": 0,\n",
        "    \"length\": 5000\n",
        "}\n",
        "#save request in response variable\n",
        "response = requests.get(url, params=params)\n",
        "\n",
        "#convert response into json\n",
        "json_data = response.json()['response']['data']\n",
        "\n",
        "#flattening the dataset\n",
        "# Convert the nested JSON object to a flat DataFrame\n",
        "df = pd.json_normalize(json_data, meta=['period', 'respondent', 'type'])\n",
        "\n",
        "# Rename columns for clarity\n",
        "df.columns = ['date', 'respondent', 'respondent_full', 'type', 'type_full', 'value', 'unit']\n",
        "\n",
        "#convert date string to datetime object, match the formatting.\n",
        "df['date'] = pd.to_datetime(df['date'], format=\"%Y-%m-%dT%H\")"
      ],
      "metadata": {
        "id": "6-0gxgG1Xh2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#imports data\n",
        "\n",
        "#start of the sql statement\n",
        "sql = (f\"INSERT INTO `{project_id}.{dataset_id}.{table_id}` VALUES \")\n",
        "#loop over whole dataframe & adds line to insert statement\n",
        "for row in df.itertuples():\n",
        "  #adding onto the sql statment given to BigQuery\n",
        "  sql = (sql +\n",
        "  f\"('{row.date}','{row.respondent}','{row.respondent_full}','{row.type}','{row.type_full}',{row.value},'{row.unit}'),\")\n",
        "\n",
        "#removing final , and adding a ;\n",
        "sql = (sql[:-1] + \";\")\n",
        "#send over the insert statement to BigQuery\n",
        "insert_job = client.query(sql)\n",
        "\n",
        "#code waits 3 seconds for the database to fully update before replacing rows\n",
        "time.sleep(3)\n",
        "\n",
        "#creates and replaces our current table with one with no duplicates (could take a while if a ton of rows)\n",
        "sql = (f\"\"\"\n",
        "create or replace table `{project_id}.{dataset_id}.{table_id}`  as (\n",
        "  select * except(row_num) from (\n",
        "      select *,\n",
        "        row_number() over ( partition by `date`, `respondent`,`respondent_full`,`type`,`type_full`,`value`,`unit` order by `date`, `respondent`,`respondent_full`,`type`,`type_full`,`value`,`unit` ) row_num\n",
        "      from\n",
        "      `{project_id}.{dataset_id}.{table_id}` ) t\n",
        "  where row_num=1\n",
        ")\n",
        "\"\"\")\n",
        "\n",
        "#send dupe check to BigQuery\n",
        "insert_job = client.query(sql)"
      ],
      "metadata": {
        "id": "oge_NWrYikMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#downloads sql data into a csv file\n",
        "#from google.colab import files\n",
        "\n",
        "#sql = f\"\"\"\n",
        "#SELECT *\n",
        "#FROM `{project_id}.{dataset_id}.{table_id}`\n",
        "#ORDER BY date DESC\n",
        "#\"\"\"\n",
        "\n",
        "#query_job = client.query(sql)\n",
        "\n",
        "#turn the response into a Pandas DataFrame\n",
        "#df = query_job.result().to_dataframe()\n",
        "\n",
        "#convert into csv file\n",
        "#df.to_csv('solvxData.csv', index=False)\n",
        "\n",
        "#DELETE COMMENT IF YOU WANT TO DOWNLOAD INFORMATION AS A CSV FILE\n",
        "#files.download(\"solvxData.csv\")"
      ],
      "metadata": {
        "id": "QXzbwlksCUml",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "74e36c84-69a2-4d41-885e-09e394d96a5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_82bbcbec-4feb-4aae-9be3-04556c174238\", \"solvxData.csv\", 21217)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}